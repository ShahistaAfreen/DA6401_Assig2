{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShahistaAfreen/DA6401_Assig2/blob/main/NA21B050_DLA2_PartA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_4RoqtAYpzp"
      },
      "source": [
        "**Q - 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90M47Jl31WH3",
        "outputId": "b75cadd7-b7b0-4660-afd2-128d4fe8081d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os, shutil, random\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/DL_A2_Dataset'\n",
        "train_path = os.path.join(dataset_path, 'train')\n",
        "validation_path = os.path.join(dataset_path, 'validation')\n",
        "\n",
        "validation_split_fraction = 0.1\n",
        "\n",
        "# Get class names from train\n",
        "class_names = os.listdir(train_path)\n",
        "class_names = list(filter(lambda x: x != \".DS_Store\", class_names))\n",
        "\n",
        "# Clean or create validation directory\n",
        "shutil.rmtree(validation_path, ignore_errors=True)\n",
        "os.makedirs(validation_path, exist_ok=True)\n",
        "\n",
        "for each_class in class_names:\n",
        "    os.makedirs(os.path.join(validation_path, each_class), exist_ok=True)\n",
        "\n",
        "    train_class_path = os.path.join(train_path, each_class)\n",
        "    images = os.listdir(train_class_path)\n",
        "    images = list(filter(lambda x: x != \".DS_Store\", images))\n",
        "\n",
        "    random.shuffle(images)\n",
        "    val_count = round(validation_split_fraction * len(images))\n",
        "    val_images = images[:val_count]\n",
        "\n",
        "    for img in val_images:\n",
        "        src = os.path.join(train_class_path, img)\n",
        "        dst = os.path.join(validation_path, each_class, img)\n",
        "        shutil.move(src, dst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X37QLCnD1cfk",
        "outputId": "86eb0edf-267e-493a-b00f-1f8bd158a6ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class names: ['Plantae', 'Fungi', 'Aves', 'Arachnida', 'Amphibia', 'Mollusca', 'Insecta', 'Reptilia', 'Mammalia', 'Animalia']\n",
            "Number of classes: 10\n",
            "Total training images: 9014\n",
            "Total test images (val/): 2000\n",
            "Total validation images (from train): 1002\n"
          ]
        }
      ],
      "source": [
        "# Define paths to training, test, and validation directories\n",
        "train_dir = os.path.join(dataset_path, 'train')\n",
        "val_dir = os.path.join(dataset_path, 'val')               # test data\n",
        "validation_dir = os.path.join(dataset_path, 'validation') # splitted from train\n",
        "\n",
        "# Retrieve class names from training folder\n",
        "class_names = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
        "print(\"Class names:\", class_names)\n",
        "\n",
        "# Count the number of classes\n",
        "num_classes = len(class_names)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Helper function to count images in a class folder\n",
        "def count_images(directory):\n",
        "    return sum(\n",
        "        1 for item in os.listdir(directory)\n",
        "        if os.path.isfile(os.path.join(directory, item)) and not item.startswith('.')\n",
        "    )\n",
        "\n",
        "# Count training, test, and validation images\n",
        "train_count = sum(count_images(os.path.join(train_dir, cls)) for cls in class_names)\n",
        "val_count    = sum(count_images(os.path.join(val_dir, cls)) for cls in class_names)\n",
        "validation_count = sum(count_images(os.path.join(validation_dir, cls)) for cls in class_names)\n",
        "\n",
        "# Output the counts\n",
        "print(f\"Total training images: {train_count}\")\n",
        "print(f\"Total test images (val/): {val_count}\")\n",
        "print(f\"Total validation images (from train): {validation_count}\")\n",
        "\n",
        "# Assign to variables\n",
        "M = train_count\n",
        "M_test = val_count\n",
        "M_val = validation_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9NR2HubOU3Y",
        "outputId": "259d1164-65f8-4299-b20e-b7a33fb1a2a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZLzXflGBHpb"
      },
      "outputs": [],
      "source": [
        "# !pip install -U numpy pytorch-lightning --quiet\n",
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao0WeORpKqyO",
        "outputId": "906cac30-e471-4e92-e228-4de9ae9c41a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.13.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.1 torchmetrics-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class CustomNeuralNetwork(pl.LightningModule):\n",
        "    def __init__(self, in_channels=3, class_count=10, conv_channel_list=[32, 64, 128, 256, 512],\n",
        "                 filter_size=3, act_function='relu', hidden_units=256, img_dimensions=224, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.activation = self.get_activation_function(act_function)\n",
        "        self.img_dimensions = img_dimensions\n",
        "\n",
        "        layers = []\n",
        "        channels = in_channels\n",
        "\n",
        "        for out_channels in conv_channel_list:\n",
        "            layers += [\n",
        "                nn.Conv2d(channels, out_channels, kernel_size=filter_size, padding=1),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "                nn.MaxPool2d(2, 2)\n",
        "            ]\n",
        "            channels = out_channels\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(*layers)\n",
        "\n",
        "        final_feature_dim = img_dimensions // (2 ** len(conv_channel_list))\n",
        "        flat_size = conv_channel_list[-1] * final_feature_dim * final_feature_dim\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(flat_size, hidden_units),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_units, class_count)\n",
        "        )\n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Preprocessing pipeline\n",
        "        self.preprocessing = transforms.Compose([\n",
        "            transforms.Resize((img_dimensions, img_dimensions)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.4712, 0.4600, 0.3896], std=[0.2406, 0.2301, 0.2406])\n",
        "        ])\n",
        "\n",
        "        # Compute stats\n",
        "        self.param_count = sum(p.numel() for p in self.parameters())\n",
        "        self.flop_count = self.calculate_flops(conv_channel_list, filter_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
        "        self.log_dict({'train_loss': loss, 'train_acc': acc}, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
        "        self.log_dict({'val_loss': loss, 'val_acc': acc}, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "\n",
        "    def get_activation_function(self, name):\n",
        "        if name == 'relu':\n",
        "            return F.relu\n",
        "        elif name == 'leaky_relu':\n",
        "            return lambda x: F.leaky_relu(x, 0.2)\n",
        "        elif name == 'gelu':\n",
        "            return F.gelu\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation: {name}\")\n",
        "\n",
        "    def calculate_flops(self, conv_channel_list, filter_size):\n",
        "        ops = 0\n",
        "        h = w = self.img_dimensions\n",
        "        c_in = self.hparams.in_channels\n",
        "\n",
        "        for c_out in conv_channel_list:\n",
        "            h //= 2\n",
        "            w //= 2\n",
        "            ops += h * w * c_in * c_out * (filter_size ** 2)\n",
        "            c_in = c_out\n",
        "\n",
        "        return ops\n",
        "\n",
        "# Usage\n",
        "if __name__ == \"__main__\":\n",
        "    model = CustomNeuralNetwork(act_function='gelu')\n",
        "    print(model)\n",
        "    print(f\"Total Parameters: {model.param_count:,}\")\n",
        "    print(f\"Total Estimated FLOPs: {model.flop_count:,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilbmwBBBKUl9",
        "outputId": "e05c0d08-5564-434f-8195-8c10cc03786e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomNeuralNetwork(\n",
            "  (feature_extractor): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            "  (loss_fn): CrossEntropyLoss()\n",
            ")\n",
            "Total Parameters: 7,995,914\n",
            "Total Estimated FLOPs: 242,049,024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNmLdY9hYweA"
      },
      "source": [
        "**Question 02**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "kmA8o-zm5kZ6",
        "outputId": "57b6d127-bf1d-458c-a6c1-f9f2b2b7af0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 123\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import wandb\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Set seed for reproducibility\n",
        "RANDOM_SEED = 123\n",
        "pl.seed_everything(RANDOM_SEED)\n",
        "\n",
        "# Activation function mapping\n",
        "ACTIVATION_FUNCTIONS = {\n",
        "    \"LeakyReLU\": nn.LeakyReLU(0.1),\n",
        "    \"ELU\": nn.ELU(),\n",
        "    \"Tanh\": nn.Tanh(),\n",
        "    \"SELU\": nn.SELU()\n",
        "}\n",
        "\n",
        "class NeuralVisionNetwork(pl.LightningModule):\n",
        "    def __init__(self, config=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # Default configuration\n",
        "        if config is None:\n",
        "            config = {\n",
        "                \"filter_count\": 64,\n",
        "                \"kernel_size\": 3,\n",
        "                \"activation\": \"LeakyReLU\",\n",
        "                \"filter_pattern\": \"pyramid\",\n",
        "                \"use_normalization\": True,\n",
        "                \"dropout_prob\": 0.2,\n",
        "                \"hidden_size\": 256,\n",
        "                \"learning_rate\": 1e-3\n",
        "            }\n",
        "\n",
        "        self.save_hyperparameters(config)\n",
        "\n",
        "        # Model parameters\n",
        "        img_size = 224\n",
        "        input_channels = 3\n",
        "        num_classes = 10\n",
        "        filter_size = config.get(\"kernel_size\", 3)\n",
        "        activation = ACTIVATION_FUNCTIONS[config.get(\"activation\", \"LeakyReLU\")]\n",
        "        use_norm = config.get(\"use_normalization\", True)\n",
        "        dropout_prob = config.get(\"dropout_prob\", 0.2)\n",
        "        filter_pattern = config.get(\"filter_pattern\", \"pyramid\")\n",
        "        base_filters = config.get(\"filter_count\", 64)\n",
        "        hidden_dim = config.get(\"hidden_size\", 256)\n",
        "        self.learning_rate = config.get(\"learning_rate\", 1e-3)\n",
        "\n",
        "        # Configure filter progression based on pattern\n",
        "        if filter_pattern == \"pyramid\":\n",
        "            filter_sizes = [base_filters * (2 ** i) for i in range(5)]\n",
        "        elif filter_pattern == \"constant\":\n",
        "            filter_sizes = [base_filters] * 5\n",
        "        else:  # inverse\n",
        "            filter_sizes = [base_filters // (2 ** i) for i in range(5)]\n",
        "            filter_sizes = [max(16, f) for f in filter_sizes]  # Ensure minimum size\n",
        "\n",
        "        # Build feature extraction layers\n",
        "        feature_layers = []\n",
        "        in_channels = input_channels\n",
        "\n",
        "        for filters in filter_sizes:\n",
        "            feature_layers.append(nn.Conv2d(in_channels, filters, filter_size, padding=1))\n",
        "            if use_norm:\n",
        "                feature_layers.append(nn.BatchNorm2d(filters))\n",
        "            feature_layers.append(activation)\n",
        "            feature_layers.append(nn.MaxPool2d(2))\n",
        "            in_channels = filters\n",
        "\n",
        "        self.feature_module = nn.Sequential(*feature_layers)\n",
        "\n",
        "        # Calculate output size after convolutions\n",
        "        output_size = img_size // (2 ** len(filter_sizes))\n",
        "        flatten_size = filter_sizes[-1] * output_size * output_size\n",
        "\n",
        "        # Classification layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(flatten_size, hidden_dim),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            activation,\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        # Loss function\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_module(x)\n",
        "        flat_features = torch.flatten(features, start_dim=1)\n",
        "        logits = self.classifier(flat_features)\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "        # Log metrics\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", accuracy, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "        # Log metrics\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", accuracy, prog_bar=True)\n",
        "        return {\"val_loss\": loss, \"val_acc\": accuracy}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "        # Log metrics\n",
        "        self.log(\"test_loss\", loss, prog_bar=True)\n",
        "        self.log(\"test_acc\", accuracy, prog_bar=True)\n",
        "        return {\"test_loss\": loss, \"test_acc\": accuracy}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
        "\n",
        "class ImageDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, train_dir, val_dir, test_dir, batch_size=32, use_augmentation=True):\n",
        "        super().__init__()\n",
        "        self.train_dir = train_dir\n",
        "        self.val_dir = val_dir\n",
        "        self.test_dir = test_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.use_augmentation = use_augmentation\n",
        "\n",
        "        # Calculate normalization statistics (approximate for natural images)\n",
        "        self.mean = [0.485, 0.456, 0.406]\n",
        "        self.std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Base transformations\n",
        "        base_transforms = [\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.mean, self.std)\n",
        "        ]\n",
        "\n",
        "        # Add augmentations for training\n",
        "        if self.use_augmentation:\n",
        "            train_transforms = [\n",
        "                transforms.RandomResizedCrop(224),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "                transforms.RandomRotation(10),\n",
        "            ] + base_transforms\n",
        "        else:\n",
        "            train_transforms = base_transforms\n",
        "\n",
        "        # Create datasets\n",
        "        self.train_dataset = ImageFolder(\n",
        "            self.train_dir,\n",
        "            transform=transforms.Compose(train_transforms)\n",
        "        )\n",
        "\n",
        "        self.val_dataset = ImageFolder(\n",
        "            self.val_dir,\n",
        "            transform=transforms.Compose(base_transforms)\n",
        "        )\n",
        "\n",
        "        self.test_dataset = ImageFolder(\n",
        "            self.test_dir,\n",
        "            transform=transforms.Compose(base_transforms)\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2,  # Reduced worker count to avoid memory issues\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2,  # Reduced worker count\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2,  # Reduced worker count\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "# Run a single training with specific hyperparameters\n",
        "def train_with_config(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        # Get configuration from W&B\n",
        "        config = dict(wandb.config)\n",
        "\n",
        "        # Update run name to reflect parameters\n",
        "        wandb.run.name = f\"{config['filter_pattern']}_{config['filter_count']}_{config['activation']}\"\n",
        "\n",
        "        # Create model and data module\n",
        "        model = NeuralVisionNetwork(config)\n",
        "        data_module = ImageDataModule(\n",
        "            train_dir,\n",
        "            val_dir,\n",
        "            test_dir,\n",
        "            batch_size=config.get('batch_size', 32),\n",
        "            use_augmentation=config.get('use_augmentation', True)\n",
        "        )\n",
        "\n",
        "        # W&B Logger\n",
        "        logger = WandbLogger(project=\"vision-model-sweep\", log_model=True)\n",
        "\n",
        "        # Callbacks\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor=\"val_acc\",\n",
        "            mode=\"max\",\n",
        "            patience=config.get('patience', 5),\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            dirpath=\"checkpoints\",\n",
        "            filename=\"best-model-{epoch:02d}-{val_acc:.4f}\",\n",
        "            monitor=\"val_acc\",\n",
        "            mode=\"max\",\n",
        "            save_top_k=1\n",
        "        )\n",
        "\n",
        "        # Create trainer - FIXED devices parameter\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=config.get('max_epochs', 15),\n",
        "            callbacks=[early_stopping, checkpoint_callback],\n",
        "            logger=logger,\n",
        "            accelerator=\"auto\",\n",
        "            # Fixed the devices parameter to specific values based on accelerator\n",
        "            devices=1,  # Always use 1 device regardless of accelerator type\n",
        "            log_every_n_steps=10\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        trainer.fit(model, datamodule=data_module)\n",
        "\n",
        "        # Test the model\n",
        "        trainer.test(model, datamodule=data_module)\n",
        "\n",
        "# Define sweep configuration\n",
        "sweep_config = {\n",
        "    'method': 'bayes',  # Bayesian optimization\n",
        "    'metric': {\n",
        "        'name': 'val_acc',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'filter_count': {\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'kernel_size': {\n",
        "            'values': [3, 5]\n",
        "        },\n",
        "        'activation': {\n",
        "            'values': ['LeakyReLU', 'ELU', 'Tanh', 'SELU']\n",
        "        },\n",
        "        'filter_pattern': {\n",
        "            'values': ['pyramid', 'constant', 'inverse']\n",
        "        },\n",
        "        'use_normalization': {\n",
        "            'values': [True, False]\n",
        "        },\n",
        "        'use_augmentation': {\n",
        "            'values': [True, False]\n",
        "        },\n",
        "        'dropout_prob': {\n",
        "            'values': [0.0, 0.1, 0.3]\n",
        "        },\n",
        "        'hidden_size': {\n",
        "            'values': [128, 256, 512]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'distribution': 'uniform',  # Changed to uniform for better compatibility\n",
        "            'min': 0.0001,\n",
        "            'max': 0.01\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [16, 32, 64]\n",
        "        },\n",
        "        'max_epochs': {\n",
        "            'value': 15\n",
        "        },\n",
        "        'patience': {\n",
        "            'value': 5\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize wandb\n",
        "    wandb.login()\n",
        "\n",
        "    # Create the sweep\n",
        "    sweep_id = wandb.sweep(sweep_config, project=\"vision-model-sweep\")\n",
        "\n",
        "    # Start the sweep agent\n",
        "    wandb.agent(sweep_id, function=train_with_config, count=2)\n",
        "\n",
        "    print(\"Hyperparameter sweep completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apfemwf-u09F"
      },
      "outputs": [],
      "source": [
        "import nbformat\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# Path to current notebook\n",
        "notebook_path = '/content/drive/MyDrive/NA21B050_DLA2_PartA.ipynb'\n",
        "\n",
        "# Load the notebook\n",
        "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Remove metadata.widgets\n",
        "if 'widgets' in nb['metadata']:\n",
        "    del nb['metadata']['widgets']\n",
        "    print(\"Removed 'metadata.widgets'\")\n",
        "else:\n",
        "    print(\"No 'metadata.widgets' found\")\n",
        "\n",
        "# Save back to the same file (or change filename)\n",
        "with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "    nbformat.write(nb, f)\n",
        "    print(\"Saved cleaned notebook\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}